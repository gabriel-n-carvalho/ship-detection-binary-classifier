# üö¢ Dete√ß√£o de Navios - Classificador Bin√°rio

Um classificador bin√°rio determin√≠stico, pronto para produ√ß√£o, para detetar navios em imagens de sat√©lite utilizando o conjunto de dados Airbus Ship Detection Challenge. Constru√≠do com PyTorch e otimizado para treino apenas em CPU em contentores Docker.

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Funcionalidades](#funcionalidades)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Pr√©-requisitos](#pr√©-requisitos)
- [In√≠cio R√°pido](#in√≠cio-r√°pido)
- [Utiliza√ß√£o](#utiliza√ß√£o)
- [Configura√ß√£o](#configura√ß√£o)
- [Detalhes do Treino](#detalhes-do-treino)
- [Processamento de Dados](#processamento-de-dados)
- [Arquitetura do Modelo](#arquitetura-do-modelo)
- [Reprodutibilidade](#reprodutibilidade)
- [Otimiza√ß√£o de Desempenho](#otimiza√ß√£o-de-desempenho)
- [Resolu√ß√£o de Problemas](#resolu√ß√£o-de-problemas)
- [Contribuir](#contribuir)
- [Licen√ßa](#licen√ßa)

## üéØ Vis√£o Geral

Este projeto transforma o complexo desafio de segmenta√ß√£o do Airbus Ship Detection num problema mais simples de classifica√ß√£o bin√°ria: **navio vs. sem navio**. √â concebido para ambientes de produ√ß√£o onde n√£o existem recursos de GPU, utilizando t√©cnicas avan√ßadas de otimiza√ß√£o para CPU e treino determin√≠stico para total reprodutibilidade.

**Principais casos de utiliza√ß√£o:**

- Vigil√¢ncia e monitoriza√ß√£o mar√≠tima
- An√°lise de imagens de sat√©lite
- Dete√ß√£o de navios em dados de dete√ß√£o remota
- Fins educativos/de investiga√ß√£o em vis√£o por computador

## ‚ú® Funcionalidades

### üöÄ **Capacidades Principais**

- **Classifica√ß√£o Bin√°ria**: Dete√ß√£o de navios (1) vs. sem navio (0)
- **Treino Determin√≠stico**: Reprodutibilidade total entre execu√ß√µes
- **Paragem Antecipada (Early Stopping)**: Com base em PR-AUC com paci√™ncia configur√°vel
- **Retoma por Checkpoint**: Retomar o treino a partir de qualquer checkpoint
- **Otimiza√ß√£o para CPU**: Otimizado para ARM64 com melhorias de threading

### üîß **Funcionalidades T√©cnicas**

- **Contentoriza√ß√£o com Docker**: Pronto para implanta√ß√£o em produ√ß√£o
- **Aumento de Dados (Data Augmentation)**: Transforma√ß√µes no treino para robustez
- **Gest√£o de Desbalanceamento de Classes**: C√°lculo autom√°tico de `pos_weight`
- **Amostragem Estratificada**: Mant√©m o equil√≠brio de classes em subconjuntos
- **Registo Abrangente**: Progresso e m√©tricas em tempo real
- **Gest√£o de Recursos**: Limites configur√°veis de mem√≥ria e CPU

### üìä **M√©tricas e Monitoriza√ß√£o**

- **M√©tricas de Treino**: Loss, taxa de aprendizagem, tempo por batch
- **M√©tricas de Valida√ß√£o**: Acur√°cia, Precis√£o, Revoca√ß√£o, F1, ROC-AUC, PR-AUC
- **Acompanhamento de Progresso**: Estimativas de ETA e barras de progresso em tempo real
- **Gest√£o de Checkpoints**: Guarda o melhor e o √∫ltimo modelo

## üìÅ Estrutura do Projeto

```
final-project/
‚îú‚îÄ‚îÄ airbus-ship-detection/          # Diret√≥rio do dataset (√© necess√°rio fazer o download no Kaggle)
‚îÇ   ‚îú‚îÄ‚îÄ train_v2/                   # Imagens de treino
‚îú‚îÄ‚îÄ labels/                         # Ficheiros de r√≥tulos e divis√µes
‚îÇ   ‚îú‚îÄ‚îÄ binary_labels.csv           # R√≥tulos bin√°rios navio/sem navio
‚îÇ   ‚îú‚îÄ‚îÄ segmentations_labels.csv    # Dados originais de segmenta√ß√£o (vem com o dataset do Kaggle)
‚îÇ   ‚îî‚îÄ‚îÄ splits/                     # Divis√µes treino/valida√ß√£o
‚îÇ       ‚îú‚îÄ‚îÄ train.csv               # Conjunto de treino
‚îÇ       ‚îî‚îÄ‚îÄ val.csv                 # Conjunto de valida√ß√£o
‚îú‚îÄ‚îÄ utils/                          # Utilit√°rios de pr√©-processamento de dados
‚îÇ   ‚îú‚îÄ‚îÄ make_binary_labels.py       # Converter segmenta√ß√£o para bin√°rio
‚îÇ   ‚îî‚îÄ‚îÄ make_train_val_split.py     # Criar divis√µes treino/valida√ß√£o
‚îú‚îÄ‚îÄ outputs/                        # Sa√≠das do modelo e checkpoints
‚îÇ   ‚îî‚îÄ‚îÄ models/                     # Checkpoints guardados
‚îú‚îÄ‚îÄ docker-compose.yml              # Orquestra√ß√£o de contentores
‚îú‚îÄ‚îÄ Dockerfile                      # Defini√ß√£o do contentor
‚îú‚îÄ‚îÄ requirements.txt                # Depend√™ncias Python
‚îú‚îÄ‚îÄ train_binary_classifier.py      # Script principal de treino
‚îî‚îÄ‚îÄ README.md                       # Este ficheiro
```

## üìã Pr√©-requisitos

### **Requisitos do Sistema**

- **SO**: Linux, macOS ou Windows com Docker
- **RAM**: M√≠nimo 16 GB, recomendado 64 GB+
- **CPU**: Processador multi‚Äëcore (ARM64 ou x86_64)
- **Armazenamento**: 10 GB+ de espa√ßo livre para dataset e modelos

### **Requisitos de Software**

- **Docker**: Vers√£o 20.10+
- **Docker Compose**: Vers√£o 2.0+
- **Git**: Para clonar o reposit√≥rio

### **Conjunto de Dados**

- **Airbus Ship Detection Challenge**: Transferir de [Kaggle](https://www.kaggle.com/c/airbus-ship-detection)

## üöÄ In√≠cio R√°pido

### **1. Clonar e Configurar**

```bash
git clone https://github.com/gabriel-n-carvalho/ship-detection-binary-classifier
cd ship-detection-binary-classifier
```

### **2. Transferir o dataset**

- Transfira o dataset do Kaggle
- Copie a pasta `train_v2/` do dataset `airbus-ship-detection` para o diret√≥rio raiz do projeto, para que a sua estrutura de pastas corresponda ao exemplo acima.
- Coloque o ficheiro de r√≥tulos de segmenta√ß√£o `train_ship_segmentations_v2.csv` em `labels/train_ship_segmentations_v2.csv`.
- Execute os seguintes comandos para converter os r√≥tulos de segmenta√ß√£o em r√≥tulos bin√°rios e criar uma divis√£o estratificada dos dados em conjuntos de treino e valida√ß√£o.

### **3. Preparar Dados**

```bash
# Converter r√≥tulos de segmenta√ß√£o para bin√°rio (se necess√°rio). Este script converte os r√≥tulos originais em r√≥tulos bin√°rios.
python utils/make_binary_labels.py

# Criar divis√µes de r√≥tulos (se ainda n√£o existirem). Este script cria uma divis√£o estratificada em treino e valida√ß√£o.
python utils/make_train_val_split.py
```

### **4. Iniciar o Treino com Docker**

```bash
# Este comando inicia o processo de treino e ver√° as barras de progresso no primeiro plano.
docker-compose run --rm efficientnet-training

```

**Nota:** Usar `docker-compose up` pode fazer com que as barras de progresso do tqdm sejam colocadas em buffer e apenas apare√ßam ap√≥s o fim do treino, devido √† forma como o output √© tratado ([ver issue #771 do tqdm](https://github.com/tqdm/tqdm/issues/771)). Para atualiza√ß√µes em tempo real, recomenda-se usar `docker-compose run`.

### **5. Monitorizar o Treino**

```bash
# Com `docker-compose run`, ver√° o progresso do tqdm em tempo real no primeiro plano.

# Se optar por usar `up`, pode seguir os logs, mas o tqdm pode n√£o atualizar em tempo real:
docker-compose logs -f

# Verificar o estado dos contentores
docker-compose ps
```

## üìñ Utiliza√ß√£o

### **Interface de Linha de Comandos**

O script de treino suporta uma configura√ß√£o extensa por linha de comandos:

```bash
python train_binary_classifier.py \
    --seed 42 \
    --fold 0 \
    --batch-size 32 \
    --epochs 100 \
    --lr 3e-4 \
    --img-size 256 \
    --grad-accum-steps 1 \
    --early-stop-patience 20 \
    --model-name tf_efficientnetv2_b0.in1k \
    --subset-size 1000
```

### **Vari√°veis de Ambiente do Docker**

Configure os par√¢metros de treino via vari√°veis de ambiente:

```bash
# Substituir valores por defeito
export SEED=123
export BATCH_SIZE=64
export EPOCHS=200
export LR=1e-4

# Iniciar treino
docker-compose up
```

### **Subconjuntos de Dados para Desenvolvimento**

Use subconjuntos de dados para itera√ß√£o mais r√°pida durante o desenvolvimento:

```bash
# Usar 10% dos dados
python train_binary_classifier.py --subset-fraction 0.1

# Usar um n√∫mero espec√≠fico de amostras
python train_binary_classifier.py --subset-size 1000
```

## ‚öôÔ∏è Configura√ß√£o

### **Hiperpar√¢metros de Treino**

| Par√¢metro             | Predefini√ß√£o | Descri√ß√£o                                   |
| --------------------- | ------------ | ------------------------------------------- |
| `SEED`                | 42           | Semente aleat√≥ria para reprodutibilidade    |
| `BATCH_SIZE`          | 32           | Tamanho do batch de treino                  |
| `EPOCHS`              | 100          | N√∫mero m√°ximo de √©pocas                     |
| `LR`                  | 3e-4         | Taxa de aprendizagem                        |
| `IMG_SIZE`            | 256          | Tamanho da imagem de entrada                |
| `GRAD_ACCUM_STEPS`    | 1            | Passos de acumula√ß√£o de gradientes          |
| `EARLY_STOP_PATIENCE` | 20           | Paci√™ncia para paragem antecipada           |

### **Arquitetura do Modelo**

- **Modelo Base**: EfficientNet-V2-B0 (pr√©‚Äëtreinado no ImageNet)
- **Tamanho de Entrada**: Imagens RGB 256x256
- **Sa√≠da**: √önico sigmoid (probabilidade 0-1)
- **Fun√ß√£o de Perda**: BCEWithLogitsLoss com balanceamento de classes

### **Aumento de Dados**

**Transforma√ß√µes de Treino:**

- Redimensionar para 256x256
- Flip horizontal aleat√≥rio (50%)
- Flip vertical aleat√≥rio (20%)
- Rota√ß√£o aleat√≥ria (¬±5¬∞)
- Varia√ß√£o de cor (color jitter)
- Normaliza√ß√£o do ImageNet

**Transforma√ß√µes de Valida√ß√£o:**

- Redimensionar para 256x256
- Normaliza√ß√£o do ImageNet

## üéì Detalhes do Treino

### **Ciclo de Treino**

1. **Inicializa√ß√£o da √âpoca**: Definir sementes aleat√≥rias, criar barras de progresso
2. **Fase de Treino**: Forward, c√°lculo de loss, backpropagation
3. **Fase de Valida√ß√£o**: Avalia√ß√£o do modelo, c√°lculo de m√©tricas
4. **Checkpoints**: Guardar o melhor modelo (PR-AUC) e o √∫ltimo checkpoint
5. **Paragem Antecipada**: Monitorizar a melhoria do PR-AUC

### **Fun√ß√£o de Perda**

```python
# Balanceamento autom√°tico de classes
pos_weight = max(1.0, negative_samples / positive_samples)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
```

### **Otimiza√ß√£o**

- **Otimizador**: AdamW com weight decay
- **Agendador**: Cosine annealing da taxa de aprendizagem
- **Clipping de Gradiente**: Clipping da norma em 1.0
- **Acumula√ß√£o de Gradientes**: Configur√°vel para batches efetivos maiores

### **M√©tricas**

- **Acur√°cia**: Acur√°cia global de classifica√ß√£o
- **Precis√£o**: Precis√£o na dete√ß√£o de navios
- **Revoca√ß√£o**: Revoca√ß√£o na dete√ß√£o de navios
- **F1-Score**: M√©dia harm√≥nica de precis√£o e revoca√ß√£o
- **ROC-AUC**: √Årea sob a curva ROC
- **PR-AUC**: √Årea sob a curva precis√£o‚Äërevoca√ß√£o (m√©trica principal)

## üîÑ Processamento de Dados

### **Pipeline de Dados**

1. **Carregamento de Imagem**: Convers√£o para RGB baseada em PIL com tratamento de erros
2. **Transforma√ß√£o**: Transforms do PyTorch com aumento de dados
3. **Batching**: DataLoader determin√≠stico com seed nos workers
4. **Transfer√™ncia para Dispositivo**: Movimenta√ß√£o de dados otimizada para CPU

### **Processamento de R√≥tulos**

- **Convers√£o Bin√°ria**: M√°scaras de segmenta√ß√£o ‚Üí r√≥tulos bin√°rios
- **Divis√£o Estratificada**: Mant√©m o equil√≠brio de classes em treino/valida√ß√£o
- **Estabilidade de Tipo**: `float32` consistente para r√≥tulos

### **Valida√ß√£o de Dados**

- **Verifica√ß√£o de Balanceamento**: Garante amostras positivas e negativas
- **Carregamento de Imagem**: Tratamento gracioso de imagens corrompidas
- **Consist√™ncia de R√≥tulos**: Valida√ß√£o do formato e valores dos r√≥tulos

## üèóÔ∏è Arquitetura do Modelo

### **EfficientNet-V2-B0**

- **Arquitetura**: Escalonamento composto com blocos residuais invertidos
- **Par√¢metros**: ~7,1M par√¢metros trein√°veis
- **Entrada**: 256x256x3 imagens RGB
- **Sa√≠da**: √önico logit para classifica√ß√£o bin√°ria
- **Pr√©‚Äëtreino**: Pesos do ImageNet‚Äë1K

### **Modifica√ß√µes no Modelo**

```python
model = timm.create_model(
    MODEL_NAME,
    pretrained=True,
    num_classes=1  # Classifica√ß√£o bin√°ria
)
```

## üîí Reprodutibilidade

### **Treino Determin√≠stico**

- **Controlo de Sementes**: Todos os geradores aleat√≥rios com a mesma seed
- **Estado do RNG**: Guarda/restaura o estado completo para retomar
- **Seed dos Workers**: Inicializa√ß√£o determin√≠stica dos workers do DataLoader
- **Sele√ß√£o de Algoritmos**: Algoritmos determin√≠sticos do PyTorch for√ßados

### **Sistema de Checkpoints**

- **Melhor Modelo**: Guardado com base na melhoria do PR-AUC
- **√öltimo Checkpoint**: Sempre guardado para retomar
- **Estado do RNG**: Preserva√ß√£o completa do estado aleat√≥rio
- **Metadados**: Configura√ß√£o do modelo e hist√≥rico de treino

## ‚ö° Otimiza√ß√£o de Desempenho

### **Otimiza√ß√£o para CPU**

- **Threading**: Configura√ß√£o √≥tima de threads OpenMP/MKL/BLAS
- **Gest√£o de Mem√≥ria**: Defini√ß√µes conservadoras de mem√≥ria partilhada
- **Carregamento de Dados**: Um √∫nico worker no Docker para evitar conflitos
- **Processamento em Batch**: Opera√ß√µes de tensores eficientes

### **Otimiza√ß√µes no Docker**

- **Limites de Recursos**: Aloca√ß√£o configur√°vel de mem√≥ria e CPU
- **Mem√≥ria Partilhada**: `shm_size` de 16 GB para estabilidade do DataLoader
- **Montagens de Volumes**: Acesso eficiente a dados e persist√™ncia
- **Vari√°veis de Ambiente**: Defini√ß√µes do PyTorch otimizadas

### **Gest√£o de Mem√≥ria**

- **Acumula√ß√£o de Gradientes**: Batches efetivos maiores
- **Limpeza de Checkpoints**: Garbage collection autom√°tica
- **Otimiza√ß√£o de Tensores**: Opera√ß√µes espec√≠ficas para CPU
- **Mem√≥ria Partilhada**: Otimiza√ß√£o de mem√≥ria no contentor Docker

## üêõ Resolu√ß√£o de Problemas

### **Problemas Comuns**

#### **Falta de Mem√≥ria (OOM)**

```bash
# Reduzir o tamanho do batch
export BATCH_SIZE=16

# Reduzir o tamanho da imagem
export IMG_SIZE=128

# Usar subconjunto de dados
--subset-size 500
```

#### **Treino Lento**

```bash
# Aumentar o batch (se a mem√≥ria permitir)
export BATCH_SIZE=64

# Reduzir o tamanho da imagem
export IMG_SIZE=128

# Usar acumula√ß√£o de gradientes
export GRAD_ACCUM_STEPS=2
```

#### **Problemas com Docker**

```bash
# Ver logs do contentor
docker-compose logs

# Reiniciar o contentor
docker-compose restart

# Ver consumo de recursos
docker stats
```

### **Modo de Depura√ß√£o**

Ativar logs verbosos para depura√ß√£o:

```bash
# Definir vari√°vel de ambiente
export PYTHONUNBUFFERED=1

# Executar com output de debug
python -u train_binary_classifier.py --subset-size 100
```

