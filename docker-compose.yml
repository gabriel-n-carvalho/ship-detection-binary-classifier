# Docker Compose file for EfficientNet training

services:
  efficientnet-training:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: efficientnet-binary-classifier
    volumes:
      # Mount data directories from local filesystem (read-only)
      - ./airbus-ship-detection:/workspace/airbus-ship-detection:ro
      - ./labels/splits:/workspace/labels/splits:ro
      - ./labels/airbus_binary_labels.csv:/workspace/labels/airbus_binary_labels.csv:ro

      # Mount output directories for persistence (read-write)
      - ./outputs:/workspace/outputs

      # Mount training script for development (enables live code changes)
      - ./train_binary_classifier.py:/workspace/train_binary_classifier.py:ro

    environment:
      # Deterministic training settings
      - PYTHONHASHSEED=0
      - PYTHONUNBUFFERED=1
      - PYTHONIOENCODING=utf-8
      - CUDA_VISIBLE_DEVICES=""
      - PYTORCH_ENABLE_MPS_FALLBACK=1
      - TQDM_MININTERVAL=0.2

      # CPU threading optimization (calculated in Dockerfile)
      - OMP_NUM_THREADS
      - MKL_NUM_THREADS
      - NUMEXPR_NUM_THREADS
      - BLAS_NUM_THREADS

      # Training parameters (can be overridden)
      - SEED=42
      - FOLD=0
      - BATCH_SIZE=32
      - EPOCHS=100
      - LR=3e-4
      - IMG_SIZE=256
      - GRAD_ACCUM_STEPS=1
      - EARLY_STOP_PATIENCE=20
      - MODEL_NAME=tf_efficientnetv2_b0.in1k

    deploy:
      resources:
        limits:
          # Adjust based on your system (64GB total available)
          memory: 48G # 75% of total RAM, leaving 16GB for system
          cpus: "12.0"
        reservations:
          memory: 16G # 25% of total RAM as minimum guarantee
          cpus: "2.0"

    # Increase shared memory to prevent DataLoader worker issues
    shm_size: 16gb

    # Allocate a TTY to improve real-time log flushing
    tty: true
    stdin_open: true

    # Command line arguments for training
    command: >
      python -u train_binary_classifier.py
      --seed ${SEED:-42}
      --fold ${FOLD:-0}
      --batch-size ${BATCH_SIZE:-32}
      --epochs ${EPOCHS:-100}
      --lr ${LR:-3e-4}
      --img-size ${IMG_SIZE:-256}
      --grad-accum-steps ${GRAD_ACCUM_STEPS:-1}
      --early-stop-patience ${EARLY_STOP_PATIENCE:-20}
      --model-name ${MODEL_NAME:-tf_efficientnetv2_b0.in1k}
      --subset-size 10000

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import torch; print('PyTorch available:', torch.__version__)",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Logging configuration for real-time output
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        # Force flush to see real-time output
        mode: "non-blocking"


